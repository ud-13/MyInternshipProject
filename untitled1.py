# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U1UVfLPEYiPXFt79lSKInkSPnxua4QiG
"""

!pip install nltk

import nltk
from nltk.corpus import movie_reviews
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import random
nltk.download('movie_reviews')
nltk.download('punkt')
nltk.download('stopwords')

from nltk import FreqDist
from nltk.classify import apply_features

from nltk.classify import NaiveBayesClassifier
from nltk.classify.util import accuracy


# movie reviews dataset
documents = [(list(movie_reviews.words(fileid)), category)
             for category in movie_reviews.categories()
             for fileid in movie_reviews.fileids(category)]

# Shuffle the documents
random.shuffle(documents)

# Preprocess the text data
def preprocess_text(words):
    stop_words = set(stopwords.words('english'))
    return [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]


documents = [(preprocess_text(words), category) for words, category in documents]



# Extract the words from the documents
all_words = [word for words, category in documents for word in words]
all_words_freq = FreqDist(all_words)


word_features = list(all_words_freq.keys())[:2000]

# Define a function to extract features from a document
def extract_features(document):
    document_words = set(document)
    features = {}
    for word in word_features:
        features[f'contains({word})'] = (word in document_words)
    return features

# Apply the feature extraction to the documents
feature_sets = [(extract_features(words), category) for words, category in documents]


# Split training and testing sets (80% training, 20% testing)
train_set, test_set = feature_sets[:1600], feature_sets[1600:]

# Train a Naive Bayes classifier
classifier = NaiveBayesClassifier.train(train_set)

# Evaluate the classifier on the test set
print(f'Accuracy: {accuracy(classifier, test_set) * 100:.2f}%')

# Print the most informative features
classifier.show_most_informative_features(10)

def analyze_sentiment(text):
    words = preprocess_text(word_tokenize(text))
    features = extract_features(words)
    return classifier.classify(features)


sample_texts = [
    "I love this movie. It's good!",
    "This is the shit film I have ever seen.",
    "The plot was okay, but the characters were boring."
]

for text in sample_texts:
    sentiment = analyze_sentiment(text)
    print(f'Text: "{text}"\nSentiment: {sentiment}\n')